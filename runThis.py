# runThis.py
# This script is the entry point for using the Frame2Prompt system.
# GPT-4oë¥¼ í™œìš©í•´ ì˜ìƒì—ì„œ í”„ë ˆì„ì„ ë¶„ì„í•˜ëŠ” ìë™í™”ëœ ë©”ì¸ ìŠ¤í¬ë¦½íŠ¸ì…ë‹ˆë‹¤.

# -------------------------------
# âœ¨ How to Run (Usage Summary)
#
# 1. Activate the virtual environment in terminal:
#    (í„°ë¯¸ë„ì—ì„œ ê°€ìƒí™˜ê²½ í™œì„±í™”)
#       source venv/bin/activate
#
# 2. Run the main pipeline:
#    (ë©”ì¸ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰)
#       python runThis.py
#
# ğŸª„ What this script does:
#    - Extracts frames from a video in the ./vid folder (skips if already exists)
#    - Sends image groups and prompts to GPT-4o for visual analysis
#    - Asks follow-up questions after all frames are analyzed
#    - Saves the conversation log including metadata and execution time
# -------------------------------

# -------------------------------
# Step 1: Video Input
# Set your target video path under ./vid
# ë¶„ì„í•  ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œë¥¼ ì§€ì •í•˜ì„¸ìš” (ì˜ˆ: ./vid/my_video.mp4)
video_path = "./vid/111.mov"

# -------------------------------
# Step 2: Frame Extraction Interval
# Set how frequently to extract frames from the video (in seconds)
# í”„ë ˆì„ì„ ëª‡ ì´ˆ ê°„ê²©ìœ¼ë¡œ ì¶”ì¶œí• ì§€ ì„¤ì •í•©ë‹ˆë‹¤
interval_seconds = 2

# -------------------------------
# Step 3: Image Grouping & Prompt
# Set how many images to include per prompt, and what prompt to use
# ì´ë¯¸ì§€ ë¬¶ìŒ í¬ê¸° ë° GPTì—ê²Œ ë³´ë‚¼ ê·¸ë£¹ë³„ í”„ë¡¬í”„íŠ¸ ì„¤ì •
group_size = 2
group_prompt = (
    "From all the images you analyzed, count or estimate how many unique cars "
    "appear in the video. Include any assumptions you make (e.g., whether the same car "
    "appears in multiple frames), and mention if you saw trucks, motorcycles, or other vehicles too."
)

# -------------------------------
# Step 4: Final Follow-Up Questions
# After all image groups are analyzed, ask GPT some summary questions
# GPT ë¶„ì„ í›„ ë˜ì§ˆ ì¢…í•© ì§ˆë¬¸ ë¦¬ìŠ¤íŠ¸
final_questions = [
    "Describe what you see in each of these images. In particular, mention any vehicles (cars, buses, motorcycles, etc.) you observe.",
    "Do you see any patterns or notable features in the vehicles?",
    "Are there any unusual or interesting aspects of the video that stand out to you?"
]

# -------------------------------
# DO NOT MODIFY BELOW UNLESS NECESSARY
# ì•„ë˜ ì½”ë“œëŠ” ì „ì²´ íŒŒì´í”„ë¼ì¸ì„ ìë™ìœ¼ë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤
# -------------------------------

import os
import json
import time
from extract_frames import extract_frames
from run_conversation import run_conversation
from conversation_with_gpt import ask_followup_question

# ğŸ“Œ Rate Limiting Setup
class RateLimiter:
    def __init__(self, requests_per_minute=20):
        self.requests_per_minute = requests_per_minute
        self.interval = 60.0 / requests_per_minute
        self.last_request_time = 0

    def wait(self):
        current_time = time.time()
        wait_time = self.interval - (current_time - self.last_request_time)
        if wait_time > 0:
            time.sleep(wait_time)
        self.last_request_time = time.time()

rate_limiter = RateLimiter(requests_per_minute=20)  # Adjust as needed

# â± Execution timer start
start_time = time.time()

# ğŸ¯ Define output folder name
trial_name = os.path.splitext(os.path.basename(video_path))[0] + "_trial"
folder_name = f"{trial_name}_{interval_seconds}s"
output_path = os.path.join("output", folder_name)

# ğŸ–¼ Step A: Extract frames (Skip if already exists)
if os.path.exists(output_path):
    print(f"ğŸ“‚ Found existing frame folder: {output_path}")
    print("ğŸ” Skipping frame extraction step.")
else:
    print("ğŸ Extracting frames...")
    extract_frames(video_path, trial_name, interval_seconds)

# ğŸ’¬ Step B: Start GPT image conversation
print("ğŸ¤– Starting GPT conversation...")
messages, summaries = run_conversation(
    trial_name=trial_name,
    interval_seconds=interval_seconds,
    group_size=group_size,
    prompt=group_prompt,
    rate_limiter=rate_limiter
)

# ğŸ§  Step C: Ask follow-up questions
print("\n=== Final overall analysis ===")
answers = ask_followup_question(messages, final_questions, rate_limiter=rate_limiter)

# ğŸ–¥ Print results to terminal
for q, a in answers:
    print(f"\n[Q] {q}\n[A] {a.strip()}")

# ğŸ“ Step D: Write to log file
os.makedirs("log", exist_ok=True)
log_data = {
    "video_name": os.path.basename(video_path),
    "interval_seconds": interval_seconds,
    "group_size": group_size,
    "group_prompt": group_prompt,
    "final_questions": [q for q, _ in answers],
    "responses": [a for _, a in answers],
    "execution_time_seconds": round(time.time() - start_time, 2)
}

# ğŸ—ƒ Generate log file name without conflict
base_log_path = os.path.join("log", f"{trial_name}_log.json")
log_path = base_log_path
count = 1
while os.path.exists(log_path):
    log_path = os.path.join("log", f"{trial_name}_log_{count}.json")
    count += 1

with open(log_path, "w") as f:
    json.dump(log_data, f, indent=2, ensure_ascii=False)

print(f"\nâœ… Log saved to {log_path}")